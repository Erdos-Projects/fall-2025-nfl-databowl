{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9adc2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6d0142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50643e88ad054d6382bf10d47136055b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading inputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0261ffea18b42ce98d234e1365d9d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading outputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (4880579, 23) Outputs: (562936, 6) Test input: (49753, 23)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "\n",
    "input_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/input_2023_w*.csv\")))\n",
    "output_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/output_2023_w*.csv\")))\n",
    "\n",
    "df_in = pd.concat((pd.read_csv(p) for p in tqdm(input_files, desc=\"loading inputs\")), ignore_index=True)\n",
    "df_out = pd.concat((pd.read_csv(p) for p in tqdm(output_files, desc=\"loading outputs\")), ignore_index=True)\n",
    "\n",
    "test_in = pd.read_csv(os.path.join(DATA_DIR, \"test_input.csv\"))\n",
    "test_template = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "print(\"Inputs:\", df_in.shape, \"Outputs:\", df_out.shape, \"Test input:\", test_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202f5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_len = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df_prethrow, gcol: list = []):\n",
    "    '''Function taking in the input features / prethrow frames and computing relevant features up to the final prethrow frame'''\n",
    "    df = df_prethrow.copy()\n",
    "    df = df[df['player_to_predict']]\n",
    "\n",
    "    df['dx_land'] = np.abs(df['ball_land_x'] - df['x'])\n",
    "    df['dy_land'] = np.abs(df['ball_land_y'] - df['y'])\n",
    "    df['dist_to_ball'] = np.sqrt((df['ball_land_x'] - df['x'])**2 + (df['ball_land_y'] - df['y'])**2)\n",
    "\n",
    "    df['velo_x'] = df['s']*np.cos(df['dir'])\n",
    "    df['velo_y'] = df['s']*np.sin(df['dir'])\n",
    "\n",
    "    \n",
    "    df[\"acc_x\"] = df.groupby(gcol)['velo_x'].diff() / frame_len\n",
    "    df[\"acc_y\"] = df.groupby(gcol)['velo_y'].diff() / frame_len\n",
    "\n",
    "   # a_T is the derivative of the scalar speed 's' (Tangential Acceleration)\n",
    "    # This is the rate of change of speed (along the path).\n",
    "    df[\"accel_tangential\"] = df.groupby(gcol)['s'].diff() / frame_len\n",
    "\n",
    "    # a_N is calculated using the given total magnitude 'a' and a_T\n",
    "    # The clip(lower=0) handles floating-point errors.\n",
    "    df[\"accel_normal\"] = np.sqrt(\n",
    "        (df[\"a\"]**2 - df[\"accel_tangential\"]**2).clip(lower=0)\n",
    "    )\n",
    "\n",
    "    # 2b. Calculate Instantaneous Jerk (1-frame lag)\n",
    "    df[\"jerk_x\"] = df.groupby(gcol)['acc_x'].diff() / frame_len\n",
    "    df[\"jerk_y\"] = df.groupby(gcol)['acc_y'].diff() / frame_len\n",
    "    df[\"jerk\"] = np.sqrt(df[\"jerk_x\"]**2 + df[\"jerk_y\"]**2) # Instantaneous Jerk Magnitude\n",
    "\n",
    "\n",
    "    # variable_to_flatten = 'jerk'\n",
    "    # num_lags = 5\n",
    "\n",
    "    # for i in range(1, num_lags + 1):\n",
    "    #     # This creates a new column for each time step in the past\n",
    "    #     # Example: 'jerk_lag_1' holds the value of 'jerk' from the previous frame.\n",
    "    #     #          'jerk_lag_5' holds the value of 'jerk' from 5 frames ago.\n",
    "    #     df[f\"{variable_to_flatten}_lag_{i}\"] = df.groupby(gcol)[variable_to_flatten].shift(i)\n",
    "\n",
    "    position_encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "    encoded_position = position_encoder.fit_transform(df[['player_position']])\n",
    "    \n",
    "    direction_encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "    encoded_direction = direction_encoder.fit_transform(df[['play_direction']])\n",
    "\n",
    "    side_encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "    encoded_side = side_encoder.fit_transform(df[['player_side']])\n",
    "\n",
    "    df_tot = pd.concat([df, encoded_position, encoded_direction, encoded_side], axis=1)\n",
    "    df_snap = df_tot[df_tot['final_frame_prediction'] == 1]\n",
    "    df_snap.drop(columns='frame_id',inplace=True)\n",
    "\n",
    "    rename_map = {\n",
    "        \"x\": \"x_last\",\n",
    "        \"y\": \"y_last\",\n",
    "        \"s\": \"s_last\",\n",
    "        \"a\": \"a_last\",\n",
    "        \"dir\": \"dir_last\",\n",
    "        \"o\": \"o_last\",\n",
    "    }\n",
    "\n",
    "    df_snap.rename(columns=rename_map,inplace=True)\n",
    "    print(df_snap.columns)\n",
    "    return df_snap\n",
    "\n",
    "def merge_tables(df_prethrow, df_postthrow ,gcol):\n",
    "    '''merge snapshots with df_out for training'''\n",
    "    df = pd.merge(df_postthrow, df_prethrow, on = gcol, how='left')\n",
    "    df['dx'] = df['x'] - df['x_last']\n",
    "    df['dy'] = df['y'] - df['y_last']\n",
    "    df[\"play_key\"] = df[\"game_id\"].astype(str) + \"_\" + df[\"play_id\"].astype(str)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e74d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(df_prethrow, df_postthrow ):\n",
    "    df_prethrow = df_prethrow.copy()  # avoid SettingWithCopyWarning\n",
    "    df_postthrow = df_postthrow.copy()\n",
    "\n",
    "    gcol = ['game_id','play_id','nfl_id']\n",
    "\n",
    "    final_frame = df_prethrow.groupby(gcol).tail(1)\n",
    "    \n",
    "    player_predict_final = final_frame[final_frame['player_to_predict']]\n",
    "    player_predict_final = player_predict_final[gcol + ['frame_id']]\n",
    "\n",
    "    is_final_frame = pd.MultiIndex.from_frame(df_prethrow[['game_id','play_id','nfl_id','frame_id']]).isin(\n",
    "        pd.MultiIndex.from_frame(player_predict_final)\n",
    "    )\n",
    "\n",
    "    df_prethrow['final_frame_prediction'] = np.where(is_final_frame, 1, 0)\n",
    "\n",
    "    df_altered = feature_engineer(df_prethrow, gcol=gcol)\n",
    "\n",
    "    df_model = merge_tables(df_prethrow = df_altered ,df_postthrow = df_postthrow,gcol = gcol)\n",
    "\n",
    "    return df_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mbubs\\AppData\\Local\\Temp\\ipykernel_22824\\1402069008.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_snap.drop(columns='frame_id',inplace=True)\n",
      "C:\\Users\\Mbubs\\AppData\\Local\\Temp\\ipykernel_22824\\1402069008.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_snap.rename(columns=rename_map,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'play_direction',\n",
      "       'absolute_yardline_number', 'player_name', 'player_height',\n",
      "       'player_weight', 'player_birth_date', 'player_position', 'player_side',\n",
      "       'player_role', 'x_last', 'y_last', 's_last', 'a_last', 'dir_last',\n",
      "       'o_last', 'num_frames_output', 'ball_land_x', 'ball_land_y',\n",
      "       'final_frame_prediction', 'dx_land', 'dy_land', 'dist_to_ball',\n",
      "       'velo_x', 'velo_y', 'acc_x', 'acc_y', 'accel_tangential',\n",
      "       'accel_normal', 'jerk_x', 'jerk_y', 'jerk', 'player_position_CB',\n",
      "       'player_position_DE', 'player_position_DT', 'player_position_FB',\n",
      "       'player_position_FS', 'player_position_ILB', 'player_position_LB',\n",
      "       'player_position_MLB', 'player_position_NT', 'player_position_OLB',\n",
      "       'player_position_QB', 'player_position_RB', 'player_position_S',\n",
      "       'player_position_SS', 'player_position_T', 'player_position_TE',\n",
      "       'player_position_WR', 'play_direction_left', 'play_direction_right',\n",
      "       'player_side_Defense', 'player_side_Offense'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_model = merge_tables(df_prethrow = df_in, df_postthrow = df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['x_last', 'y_last', 's_last', 'a_last', 'dir_last',\n",
    "       'o_last', 'num_frames_output', 'ball_land_x', 'ball_land_y',\n",
    "       'final_frame_prediction', 'dx_land', 'dy_land', 'dist_to_ball',\n",
    "       'velo_x', 'velo_y', 'acc_x', 'acc_y', 'accel_tangential',\n",
    "       'accel_normal', 'jerk_x', 'jerk_y', 'jerk']\n",
    "\n",
    "cat_features = ['player_position_CB',\n",
    "       'player_position_DE', 'player_position_DT', 'player_position_FB',\n",
    "       'player_position_FS', 'player_position_ILB', 'player_position_LB',\n",
    "       'player_position_MLB', 'player_position_NT', 'player_position_OLB',\n",
    "       'player_position_QB', 'player_position_RB', 'player_position_S',\n",
    "       'player_position_SS', 'player_position_T', 'player_position_TE',\n",
    "       'player_position_WR', 'play_direction_left', 'play_direction_right',\n",
    "       'player_side_Defense', 'player_side_Offense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a35414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model[numeric_features + cat_features]\n",
    "y_dx = df_model['dx']\n",
    "y_dy = df_model['dy']\n",
    "groups = df_model[\"play_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 ---\n",
      "Validation RMSEY: 2.8670\n",
      "Validation RMSEX: 3.1124\n",
      "--- Fold 2 ---\n",
      "Validation RMSEY: 2.9073\n",
      "Validation RMSEX: 3.0708\n",
      "--- Fold 3 ---\n",
      "Validation RMSEY: 2.8046\n",
      "Validation RMSEX: 3.1441\n",
      "--- Fold 4 ---\n",
      "Validation RMSEY: 2.7789\n",
      "Validation RMSEX: 3.0387\n",
      "--- Fold 5 ---\n",
      "Validation RMSEY: 2.8640\n",
      "Validation RMSEX: 3.0946\n"
     ]
    }
   ],
   "source": [
    "def model_train():\n",
    "    n_splits = 5\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "\n",
    "    model_y = LinearRegression()\n",
    "    model_x = LinearRegression()\n",
    "    fold_scores = np.zeros((2,n_splits))\n",
    "\n",
    "    # Loop through the folds generated by GroupKFold\n",
    "    # X is features, y is target, and groups is the multi-key column\n",
    "    for fold_idx, (train_index, val_index) in enumerate(gkf.split(X, groups=groups)):\n",
    "        print(f\"--- Fold {fold_idx + 1} ---\")\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_dy_train, y_dy_val = y_dy.iloc[train_index], y_dy.iloc[val_index]\n",
    "        y_dx_train, y_dx_val = y_dx.iloc[train_index], y_dx.iloc[val_index]\n",
    "        # Optional: Verify group separation (should print unique groups in each set)\n",
    "        # print(f\"Train Groups: {groups.iloc[train_index].unique()}\")\n",
    "        # print(f\"Validation Groups: {groups.iloc[val_index].unique()}\")\n",
    "\n",
    "        # Train the model\n",
    "        model_y.fit(X_train, y_dy_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        dy_y_pred = model_y.predict(X_val)\n",
    "        rmse_y = np.sqrt(mean_squared_error(y_dy_val, dy_y_pred))\n",
    "        fold_scores[0,fold_idx] = rmse_y\n",
    "\n",
    "        # Train the model\n",
    "        model_x.fit(X_train, y_dx_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        dy_x_pred = model_x.predict(X_val)\n",
    "        rmse_x = np.sqrt(mean_squared_error(y_dx_val, dy_x_pred))\n",
    "        fold_scores[1,fold_idx] = rmse_x\n",
    "        \n",
    "        print(f\"Validation RMSEY: {rmse_y:.4f}\")\n",
    "        print(f\"Validation RMSEX: {rmse_x:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc89c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da8501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fca94f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_in.loc[(df_in['game_id'] ==2023090700) & (df_in['play_id'] == 101) & (df_in['nfl_id'] == 46137), :]\n",
    "y = df_out.loc[(df_out['game_id'] ==2023090700) & (df_out['play_id'] == 101) & (df_out['nfl_id'] == 46137),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea36d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f63fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64485e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8c7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3bc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84363542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b453fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if in a comfortable spot in the project try to seperate model files from data cleaning/ transform to readibility and conciseness of the file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
