{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9adc2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6d0142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4110d2aadf344f4f9bd8c1b4922e033d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading inputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392f912be37a4a6893b7a0f24400b743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading outputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (4880579, 23) Outputs: (562936, 6) Test input: (49753, 23)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "\n",
    "input_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/input_2023_w*.csv\")))\n",
    "output_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/output_2023_w*.csv\")))\n",
    "\n",
    "df_in = pd.concat((pd.read_csv(p) for p in tqdm(input_files, desc=\"loading inputs\")), ignore_index=True)\n",
    "df_out = pd.concat((pd.read_csv(p) for p in tqdm(output_files, desc=\"loading outputs\")), ignore_index=True)\n",
    "\n",
    "test_in = pd.read_csv(os.path.join(DATA_DIR, \"test_input.csv\"))\n",
    "test_template = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "print(\"Inputs:\", df_in.shape, \"Outputs:\", df_out.shape, \"Test input:\", test_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202f5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_len = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cffe86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df_prethrow, gcol: list = []):\n",
    "    '''Function taking in the input features / prethrow frames and computing relevant features up to the final prethrow frame'''\n",
    "    df = df_prethrow.copy()\n",
    "    df = df[df['player_to_predict']]\n",
    "\n",
    "    df['dx_land'] = np.abs(df['ball_land_x'] - df['x'])\n",
    "    df['dy_land'] = np.abs(df['ball_land_y'] - df['y'])\n",
    "    df['dist_to_ball'] = np.sqrt((df['ball_land_x'] - df['x'])**2 + (df['ball_land_y'] - df['y'])**2)\n",
    "\n",
    "    df['velo_x'] = df['s']*np.cos(df['dir'])\n",
    "    df['velo_y'] = df['s']*np.sin(df['dir'])\n",
    "\n",
    "    \n",
    "    df[\"acc_x\"] = df.groupby(gcol)['velo_x'].diff() / frame_len\n",
    "    df[\"acc_y\"] = df.groupby(gcol)['velo_y'].diff() / frame_len\n",
    "\n",
    "   # a_T is the derivative of the scalar speed 's' (Tangential Acceleration)\n",
    "    # This is the rate of change of speed (along the path).\n",
    "    df[\"accel_tangential\"] = df.groupby(gcol)['s'].diff() / frame_len\n",
    "\n",
    "    # a_N is calculated using the given total magnitude 'a' and a_T\n",
    "    # The clip(lower=0) handles floating-point errors.\n",
    "    df[\"accel_normal\"] = np.sqrt(\n",
    "        (df[\"a\"]**2 - df[\"accel_tangential\"]**2).clip(lower=0)\n",
    "    )\n",
    "\n",
    "    # 2b. Calculate Instantaneous Jerk (1-frame lag)\n",
    "    df[\"jerk_x\"] = df.groupby(gcol)['acc_x'].diff() / frame_len\n",
    "    df[\"jerk_y\"] = df.groupby(gcol)['acc_y'].diff() / frame_len\n",
    "    df[\"jerk\"] = np.sqrt(df[\"jerk_x\"]**2 + df[\"jerk_y\"]**2) # Instantaneous Jerk Magnitude\n",
    "\n",
    "\n",
    "    # variable_to_flatten = 'jerk'\n",
    "    # num_lags = 5\n",
    "\n",
    "    # for i in range(1, num_lags + 1):\n",
    "    #     # This creates a new column for each time step in the past\n",
    "    #     # Example: 'jerk_lag_1' holds the value of 'jerk' from the previous frame.\n",
    "    #     #          'jerk_lag_5' holds the value of 'jerk' from 5 frames ago.\n",
    "    #     df[f\"{variable_to_flatten}_lag_{i}\"] = df.groupby(gcol)[variable_to_flatten].shift(i)\n",
    "\n",
    "    df['player_position'] = df['player_position'].astype('category')\n",
    "    df['play_direction'] = df['play_direction'].astype('category')\n",
    "    df['player_side'] = df['player_side'].astype('category')    \n",
    "\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy[df_copy['final_frame_prediction'] == 1]\n",
    "    df_copy.drop(columns='frame_id',inplace=True)\n",
    "\n",
    "    rename_map = {\n",
    "        \"x\": \"x_last\",\n",
    "        \"y\": \"y_last\",\n",
    "        \"s\": \"s_last\",\n",
    "        \"a\": \"a_last\",\n",
    "        \"dir\": \"dir_last\",\n",
    "        \"o\": \"o_last\",\n",
    "    }\n",
    "\n",
    "    df_copy.rename(columns=rename_map,inplace=True)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def merge_tables(df_prethrow, df_postthrow ,gcol, train = True):\n",
    "    '''merge snapshots with df_out for training'''\n",
    "    df = pd.merge(df_postthrow, df_prethrow, on = gcol, how='left')\n",
    "    df['dx'] = df['x'] - df['x_last']\n",
    "    df['dy'] = df['y'] - df['y_last']\n",
    "    if train == False:\n",
    "        df[\"id\"] = df[\"game_id\"].astype(str) + \"_\" + df[\"play_id\"].astype(str) + \"_\" + df[\"nfl_id\"].astype(str) + \"_\" + df[\"frame_id\"].astype(str)\n",
    "    else:    \n",
    "        df[\"play_key\"] = df[\"game_id\"].astype(str) + \"_\" + df[\"play_id\"].astype(str)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "60e74d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(df_prethrow, df_postthrow, train ):\n",
    "    df_prethrow = df_prethrow.copy()  # avoid SettingWithCopyWarning\n",
    "    df_postthrow = df_postthrow.copy()\n",
    "\n",
    "    gcol = ['game_id','play_id','nfl_id']\n",
    "\n",
    "    final_frame = df_prethrow.groupby(gcol).tail(1)\n",
    "    \n",
    "    player_predict_final = final_frame[final_frame['player_to_predict']]\n",
    "    player_predict_final = player_predict_final[gcol + ['frame_id']]\n",
    "\n",
    "    is_final_frame = pd.MultiIndex.from_frame(df_prethrow[['game_id','play_id','nfl_id','frame_id']]).isin(\n",
    "        pd.MultiIndex.from_frame(player_predict_final)\n",
    "    )\n",
    "\n",
    "    df_prethrow['final_frame_prediction'] = np.where(is_final_frame, 1, 0)\n",
    "\n",
    "    df_altered = feature_engineer(df_prethrow, gcol=gcol)\n",
    "\n",
    "    df_model = merge_tables(df_prethrow = df_altered ,df_postthrow = df_postthrow,gcol = gcol, train=train)\n",
    "\n",
    "    return df_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ffeeab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = feature_process(df_prethrow = df_in, df_postthrow = df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5cc8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['frame_id','x_last', 'y_last', 's_last', 'a_last', 'dir_last',\n",
    "       'o_last', 'ball_land_x', 'ball_land_y',\n",
    "       'dx_land', 'dy_land', 'dist_to_ball',\n",
    "       'velo_x', 'velo_y', 'acc_x', 'acc_y', 'accel_tangential',\n",
    "       'accel_normal', 'jerk_x', 'jerk_y', 'jerk']\n",
    "\n",
    "cat_features = ['play_direction', 'player_position', 'player_side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a35414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[numeric_features + cat_features]\n",
    "y_dx = train_df['dx']\n",
    "y_dy = train_df['dy']\n",
    "groups = train_df[\"play_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(args):\n",
    "    n_splits = 5\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    fold_scores = np.zeros((2,n_splits))\n",
    "\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(gkf.split(X, groups=groups)):\n",
    "        print(f\"--- Fold {fold_idx + 1} ---\")\n",
    "\n",
    "        model_y = XGBRegressor(**args)\n",
    "        model_x = XGBRegressor(**args)  \n",
    "\n",
    "        # split\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_dy_train, y_dy_val = y_dy[train_index], y_dy[val_index]\n",
    "        y_dx_train, y_dx_val = y_dx[train_index], y_dx[val_index]\n",
    "    \n",
    "        model_y.fit(\n",
    "            X_train, y_dy_train,\n",
    "            eval_set=[(X_val, y_dy_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        model_x.fit(\n",
    "            X_train, y_dx_train,\n",
    "            eval_set=[(X_val, y_dx_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # predict & score\n",
    "        dy_y_pred = model_y.predict(X_val)\n",
    "        rmse_y = np.sqrt(mean_squared_error(y_dy_val, dy_y_pred))\n",
    "        fold_scores[0, fold_idx] = rmse_y\n",
    "\n",
    "        dy_x_pred = model_x.predict(X_val)\n",
    "        rmse_x = np.sqrt(mean_squared_error(y_dx_val, dy_x_pred))\n",
    "        fold_scores[1, fold_idx] = rmse_x\n",
    "\n",
    "        print(f\"Validation RMSE_y: {rmse_y:.4f}\")\n",
    "        print(f\"Validation RMSE_x: {rmse_x:.4f}\")\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tune():\n",
    "    \n",
    "    xgb_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 12,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    'enable_categorical' : True\n",
    "}\n",
    "\n",
    "    ### return the best parameter setup\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04098abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kaggle_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# When your notebook is run on the hidden test set, inference_server.serve must be called within 10 minutes of the notebook starting\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# first `predict` call, which does not have the usual 5 minute response deadline.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m inference_server = \u001b[43mkaggle_evaluation\u001b[49m.nfl_inference_server.NFLInferenceServer(predict)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.getenv(\u001b[33m'\u001b[39m\u001b[33mKAGGLE_IS_COMPETITION_RERUN\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     36\u001b[39m     inference_server.serve()\n",
      "\u001b[31mNameError\u001b[39m: name 'kaggle_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame | pd.DataFrame:\n",
    "    predict_df = feature_process(\n",
    "        test_input.to_pandas(copy=True),\n",
    "        test.to_pandas(copy=True),\n",
    "        train=False\n",
    "    )\n",
    "\n",
    "    X = predict_df[numeric_features + cat_features]\n",
    "\n",
    "    dx_pred = model_x.predict(X)\n",
    "    dy_pred = model_y.predict(X)\n",
    "\n",
    "    \n",
    "    x_out = dx_pred + predict_df[\"x_last\"].to_numpy()\n",
    "    y_out = dy_pred + predict_df[\"y_last\"].to_numpy()\n",
    "\n",
    "    \n",
    "    ids = predict_df[\"id\"].to_pandas() \n",
    "    predictions = pd.DataFrame({\"id\": ids, \"x\": x_out, \"y\": y_out})\n",
    "\n",
    "    assert isinstance(predictions, (pd.DataFrame, pl.DataFrame))\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# When your notebook is run on the hidden test set, inference_server.serve must be called within 10 minutes of the notebook starting\n",
    "# or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very\n",
    "# first `predict` call, which does not have the usual 5 minute response deadline.\n",
    "import kaggle_evaluation.nfl_inference_server\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b453fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if in a comfortable spot in the project try to seperate model files from data cleaning/ transform to readibility and conciseness of the file \n",
    "\n",
    "# hyper param tune\n",
    "# more features, spatial and lagged terms, better notion for frame_id?\n",
    "# figure out submission, ie saving model\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
