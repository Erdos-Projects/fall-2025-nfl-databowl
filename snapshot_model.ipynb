{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adc2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6d0142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7761032abb4686949d203169d6b93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading inputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6027639df883497194842848030e086b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading outputs:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: (4880579, 23) Outputs: (562936, 6) Test input: (49753, 23)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "\n",
    "input_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/input_2023_w*.csv\")))\n",
    "output_files = sorted(glob.glob(os.path.join(DATA_DIR, \"train/output_2023_w*.csv\")))\n",
    "\n",
    "df_in = pd.concat((pd.read_csv(p) for p in tqdm(input_files, desc=\"loading inputs\")), ignore_index=True)\n",
    "df_out = pd.concat((pd.read_csv(p) for p in tqdm(output_files, desc=\"loading outputs\")), ignore_index=True)\n",
    "\n",
    "test_in = pd.read_csv(os.path.join(DATA_DIR, \"test_input.csv\"))\n",
    "test_template = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "print(\"Inputs:\", df_in.shape, \"Outputs:\", df_out.shape, \"Test input:\", test_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cffe86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df_prethrow, gcol: list = []):\n",
    "    '''Function taking in the input features / prethrow frames and computing relevant features up to the final prethrow frame'''\n",
    "    df = df_prethrow.copy()\n",
    "    df = df[df['player_to_predict']]\n",
    "\n",
    "    df['dx_land'] = np.abs(df['ball_land_x'] - df['x'])\n",
    "    df['dy_land'] = np.abs(df['ball_land_y'] - df['y'])\n",
    "    df['dist_to_ball'] = np.sqrt((df['ball_land_x'] - df['x'])**2 + (df['ball_land_y'] - df['y'])**2)\n",
    "\n",
    "    df['velo_x'] = df['s']*np.cos(df['dir'])\n",
    "    df['velo_y'] = df['s']*np.sin(df['dir'])\n",
    "\n",
    "    \n",
    "    df[\"acc_x\"] = df.groupby(gcol)['velo_x'].diff() / frame_len\n",
    "    df[\"acc_y\"] = df.groupby(gcol)['velo_y'].diff() / frame_len\n",
    "\n",
    "   # a_T is the derivative of the scalar speed 's' (Tangential Acceleration)\n",
    "    # This is the rate of change of speed (along the path).\n",
    "    df[\"accel_tangential\"] = df.groupby(gcol)['s'].diff() / frame_len\n",
    "\n",
    "    # a_N is calculated using the given total magnitude 'a' and a_T\n",
    "    # The clip(lower=0) handles floating-point errors.\n",
    "    df[\"accel_normal\"] = np.sqrt(\n",
    "        (df[\"a\"]**2 - df[\"accel_tangential\"]**2).clip(lower=0)\n",
    "    )\n",
    "\n",
    "    # 2b. Calculate Instantaneous Jerk (1-frame lag)\n",
    "    df[\"jerk_x\"] = df.groupby(gcol)['acc_x'].diff() / frame_len\n",
    "    df[\"jerk_y\"] = df.groupby(gcol)['acc_y'].diff() / frame_len\n",
    "    df[\"jerk\"] = np.sqrt(df[\"jerk_x\"]**2 + df[\"jerk_y\"]**2) # Instantaneous Jerk Magnitude\n",
    "\n",
    "\n",
    "    # variable_to_flatten = 'jerk'\n",
    "    # num_lags = 5\n",
    "\n",
    "    # for i in range(1, num_lags + 1):\n",
    "    #     # This creates a new column for each time step in the past\n",
    "    #     # Example: 'jerk_lag_1' holds the value of 'jerk' from the previous frame.\n",
    "    #     #          'jerk_lag_5' holds the value of 'jerk' from 5 frames ago.\n",
    "    #     df[f\"{variable_to_flatten}_lag_{i}\"] = df.groupby(gcol)[variable_to_flatten].shift(i)\n",
    "\n",
    "    df['player_position'] = df['player_position'].astype('category')\n",
    "    df['play_direction'] = df['play_direction'].astype('category')\n",
    "    df['player_side'] = df['player_side'].astype('category')    \n",
    "\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy[df_copy['final_frame_prediction'] == 1]\n",
    "    df_copy.drop(columns='frame_id',inplace=True)\n",
    "\n",
    "    rename_map = {\n",
    "        \"x\": \"x_last\",\n",
    "        \"y\": \"y_last\",\n",
    "        \"s\": \"s_last\",\n",
    "        \"a\": \"a_last\",\n",
    "        \"dir\": \"dir_last\",\n",
    "        \"o\": \"o_last\",\n",
    "    }\n",
    "\n",
    "    df_copy.rename(columns=rename_map,inplace=True)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def merge_tables(df_prethrow, df_postthrow ,gcol, train = True):\n",
    "    '''merge snapshots with df_out for training'''\n",
    "    df = pd.merge(df_postthrow, df_prethrow, on = gcol, how='left')\n",
    "    \n",
    "    if train:\n",
    "        if ('x' in df.columns) and ('y' in df.columns):\n",
    "            df['dx'] = df['x'] - df['x_last']\n",
    "            df['dy'] = df['y'] - df['y_last']\n",
    "        df[\"play_key\"] = (\n",
    "            df[\"game_id\"].astype(str) + \"_\" +\n",
    "            df[\"play_id\"].astype(str)\n",
    "        )\n",
    "    else:\n",
    "        df[\"id\"] = (\n",
    "            df[\"game_id\"].astype(str) + \"_\" +\n",
    "            df[\"play_id\"].astype(str) + \"_\" +\n",
    "            df[\"nfl_id\"].astype(str) + \"_\" +\n",
    "            df[\"frame_id\"].astype(str)\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60e74d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(df_prethrow, df_postthrow, train ):\n",
    "    df_prethrow = df_prethrow.copy()  # avoid SettingWithCopyWarning\n",
    "    df_postthrow = df_postthrow.copy()\n",
    "\n",
    "    gcol = ['game_id','play_id','nfl_id']\n",
    "\n",
    "    final_frame = df_prethrow.groupby(gcol).tail(1)\n",
    "    \n",
    "    player_predict_final = final_frame[final_frame['player_to_predict']]\n",
    "    player_predict_final = player_predict_final[gcol + ['frame_id']]\n",
    "\n",
    "    is_final_frame = pd.MultiIndex.from_frame(df_prethrow[['game_id','play_id','nfl_id','frame_id']]).isin(\n",
    "        pd.MultiIndex.from_frame(player_predict_final)\n",
    "    )\n",
    "\n",
    "    df_prethrow['final_frame_prediction'] = np.where(is_final_frame, 1, 0)\n",
    "\n",
    "    df_altered = feature_engineer(df_prethrow, gcol=gcol)\n",
    "\n",
    "    df_model = merge_tables(df_prethrow = df_altered ,df_postthrow = df_postthrow,gcol = gcol, train=train)\n",
    "\n",
    "    return df_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a1d6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_search(args, train_df):\n",
    "    X = train_df[numeric_features + cat_features]\n",
    "    y_dx = train_df['dx']\n",
    "    y_dy = train_df['dy']\n",
    "    n_splits = 5\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    fold_scores = np.zeros((2,n_splits))\n",
    "    groups = train_df['play_key']\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(gkf.split(X, groups=groups)):\n",
    "        print(f\"--- Fold {fold_idx + 1} ---\")\n",
    "\n",
    "        model_y = XGBRegressor(**args)\n",
    "        model_x = XGBRegressor(**args)  \n",
    "\n",
    "        # split\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_dy_train, y_dy_val = y_dy[train_index], y_dy[val_index]\n",
    "        y_dx_train, y_dx_val = y_dx[train_index], y_dx[val_index]\n",
    "    \n",
    "        model_y.fit(\n",
    "            X_train, y_dy_train,\n",
    "            eval_set=[(X_val, y_dy_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        model_x.fit(\n",
    "            X_train, y_dx_train,\n",
    "            eval_set=[(X_val, y_dx_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # predict & score\n",
    "        dy_y_pred = model_y.predict(X_val)\n",
    "        rmse_y = np.sqrt(mean_squared_error(y_dy_val, dy_y_pred))\n",
    "        fold_scores[0, fold_idx] = rmse_y\n",
    "\n",
    "        dy_x_pred = model_x.predict(X_val)\n",
    "        rmse_x = np.sqrt(mean_squared_error(y_dx_val, dy_x_pred))\n",
    "        fold_scores[1, fold_idx] = rmse_x\n",
    "\n",
    "        print(f\"Validation RMSE_y: {rmse_y:.4f}\")\n",
    "        print(f\"Validation RMSE_x: {rmse_x:.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3abc89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tune():\n",
    "    \n",
    "    xgb_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 12,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    'enable_categorical' : True\n",
    "}\n",
    "\n",
    "    ### return the best parameter setup\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e400c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    global model_dx, model_dy, numeric_features, cat_features, frame_len\n",
    "\n",
    "    frame_len = 0.1\n",
    "\n",
    "    # features\n",
    "    \n",
    "    numeric_features = [\n",
    "        'frame_id','x_last','y_last','s_last','a_last','dir_last','o_last',\n",
    "        'ball_land_x','ball_land_y','dx_land','dy_land','dist_to_ball',\n",
    "        'velo_x','velo_y','acc_x','acc_y','accel_tangential','accel_normal',\n",
    "        'jerk_x','jerk_y','jerk'\n",
    "    ]\n",
    "\n",
    "    cat_features = ['play_direction','player_position','player_side']\n",
    "\n",
    "    train_df = feature_process(df_in, df_out, train=True)\n",
    "    X_tr = train_df[numeric_features + cat_features]\n",
    "    y_dx = train_df['dx']\n",
    "    y_dy = train_df['dy']\n",
    "\n",
    "    xgb_params = {\n",
    "        \"n_estimators\": 1000, \"learning_rate\": 0.05, \"max_depth\": 12,\n",
    "        \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 1.0, \"tree_method\": \"hist\", \"n_jobs\": -1,\n",
    "        \"random_state\": 42, \"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\",\n",
    "        \"enable_categorical\": True,\n",
    "    }\n",
    "\n",
    "    \n",
    "    model_dx = XGBRegressor(**xgb_params).fit(X_tr, y_dx, verbose=False)\n",
    "    model_dy = XGBRegressor(**xgb_params).fit(X_tr, y_dy, verbose=False)\n",
    "\n",
    "    \n",
    "    test_pd       = test.to_pandas()       if hasattr(test, \"to_pandas\") else test\n",
    "    test_input_pd = test_input.to_pandas() if hasattr(test_input, \"to_pandas\") else test_input\n",
    "\n",
    "    predict_df = feature_process(test_input_pd, test_pd, train=False)\n",
    "\n",
    "    X = predict_df[numeric_features + cat_features]\n",
    "\n",
    "    dx_pred = model_dx.predict(X)\n",
    "    dy_pred = model_dy.predict(X)\n",
    "\n",
    "    x_out = dx_pred + predict_df[\"x_last\"].to_numpy()\n",
    "    y_out = dy_pred + predict_df[\"y_last\"].to_numpy()\n",
    "\n",
    "    ids = predict_df[\"id\"].astype(\"string\")\n",
    "    predictions = pd.DataFrame({\"id\": ids, \"x\": x_out, \"y\": y_out}).astype(\n",
    "        {\"id\": \"string\", \"x\": \"float64\", \"y\": \"float64\"}\n",
    "    )\n",
    "\n",
    "    predictions.to_parquet(\"submission.parquet\", index=False)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e763c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024120805_74_54586_1</td>\n",
       "      <td>88.307486</td>\n",
       "      <td>34.468627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024120805_74_54586_2</td>\n",
       "      <td>88.565310</td>\n",
       "      <td>34.375287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024120805_74_54586_3</td>\n",
       "      <td>88.909349</td>\n",
       "      <td>34.327157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024120805_74_54586_4</td>\n",
       "      <td>89.269918</td>\n",
       "      <td>34.362529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024120805_74_54586_5</td>\n",
       "      <td>89.497524</td>\n",
       "      <td>34.307499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>2025010515_3902_55112_26</td>\n",
       "      <td>99.177287</td>\n",
       "      <td>25.094266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>2025010515_3902_55112_27</td>\n",
       "      <td>99.597785</td>\n",
       "      <td>25.411971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>2025010515_3902_55112_28</td>\n",
       "      <td>100.270486</td>\n",
       "      <td>25.457553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>2025010515_3902_55112_29</td>\n",
       "      <td>100.765265</td>\n",
       "      <td>25.528334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>2025010515_3902_55112_30</td>\n",
       "      <td>101.243678</td>\n",
       "      <td>25.487121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id           x          y\n",
       "0        2024120805_74_54586_1   88.307486  34.468627\n",
       "1        2024120805_74_54586_2   88.565310  34.375287\n",
       "2        2024120805_74_54586_3   88.909349  34.327157\n",
       "3        2024120805_74_54586_4   89.269918  34.362529\n",
       "4        2024120805_74_54586_5   89.497524  34.307499\n",
       "...                        ...         ...        ...\n",
       "5832  2025010515_3902_55112_26   99.177287  25.094266\n",
       "5833  2025010515_3902_55112_27   99.597785  25.411971\n",
       "5834  2025010515_3902_55112_28  100.270486  25.457553\n",
       "5835  2025010515_3902_55112_29  100.765265  25.528334\n",
       "5836  2025010515_3902_55112_30  101.243678  25.487121\n",
       "\n",
       "[5837 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_template, test_in) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999de31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_evaluation.nfl_inference_server\n",
    "inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b453fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv successfully written.\n"
     ]
    }
   ],
   "source": [
    "#if in a comfortable spot in the project try to seperate model files from data cleaning/ transform to readibility and conciseness of the file \n",
    "\n",
    "# hyper param tune\n",
    "# more features, spatial and lagged terms, better notion for frame_id?\n",
    "# figure out submission, ie saving model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sports",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
